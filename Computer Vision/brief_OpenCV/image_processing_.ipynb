{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement d'images : filtrage, seuillage, et comptage d'objets avec opencv\n",
    "\n",
    "Une initiation à la biblithèque opencv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veille technologique: Opencv python\n",
    "\n",
    "-  Suivre les instructions et faire une recherche selon ce qui est demandé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.22.0-cp310-cp310-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in c:\\users\\dhimb\\anaconda3\\envs\\codeah\\lib\\site-packages (from scikit-image) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\dhimb\\anaconda3\\envs\\codeah\\lib\\site-packages (from scikit-image) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\dhimb\\anaconda3\\envs\\codeah\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\dhimb\\anaconda3\\envs\\codeah\\lib\\site-packages (from scikit-image) (10.0.1)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\dhimb\\anaconda3\\envs\\codeah\\lib\\site-packages (from scikit-image) (2.34.0)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image)\n",
      "  Downloading tifffile-2024.2.12-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\dhimb\\anaconda3\\envs\\codeah\\lib\\site-packages (from scikit-image) (23.1)\n",
      "Collecting lazy_loader>=0.3 (from scikit-image)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading scikit_image-0.22.0-cp310-cp310-win_amd64.whl (24.5 MB)\n",
      "   ---------------------------------------- 0.0/24.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.7/24.5 MB 23.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.5/24.5 MB 31.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 4.4/24.5 MB 35.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.3/24.5 MB 36.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.1/24.5 MB 36.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 10.1/24.5 MB 38.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.0/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 13.9/24.5 MB 43.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.4/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 17.4/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.3/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.2/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.2/24.5 MB 43.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.5/24.5 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.2.12-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 215.0/224.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 224.5/224.5 kB 2.7 MB/s eta 0:00:00\n",
      "Installing collected packages: tifffile, lazy_loader, scikit-image\n",
      "Successfully installed lazy_loader-0.4 scikit-image-0.22.0 tifffile-2024.2.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use opencv to load and display the image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "from skimage.io import imread, imshow, imsave\n",
    "\n",
    "# lire l'image (avec imread)\n",
    "image = cv2.imread('bois.png',1)\n",
    "# afficher image\n",
    "cv2.imshow('Image Testing', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1365, 2048, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# afficher la taille de l'image\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs des couleurs pour le pixel (150, 100) : Rouge (R) = 155, Vert (G) = 102, Bleu (B) = 62\n"
     ]
    }
   ],
   "source": [
    "# l'image a trois couleur R,G,B. afficher les valeurs des trois couleurs pour le pixel x = 150, et y = 100\n",
    "\n",
    "b, g, r = image[100, 150] # Notez que c'est d'abord y (hauteur), puis x (largeur)\n",
    "\n",
    "print(f'Valeurs des couleurs pour le pixel (150, 100) : Rouge (R) = {r}, Vert (G) = {g}, Bleu (B) = {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop une partie de l'image (sélectionner une petite partie à partir des coordonnées)\n",
    "\n",
    "x = 100  # Coordonnée x du coin supérieur gauche\n",
    "y = 50   # Coordonnée y du coin supérieur gauche\n",
    "\n",
    "# Largeur et hauteur du rectangle de sélection\n",
    "width = 200   # Largeur du rectangle\n",
    "height = 150  # Hauteur du rectangle\n",
    "\n",
    "# Découper la région d'intérêt (ROI) de l'image\n",
    "roi = image[y:y+height, x:x+width]\n",
    "\n",
    "# Afficher l'image originale et la région d'intérêt (ROI) recadrée\n",
    "cv2.imshow('Image originale', image)\n",
    "cropped = cv2.imshow('Region d\\'interet (ROI) recadree', roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redimensioner l'image à 200x200 pixels\n",
    "\n",
    "# Définir la nouvelle taille désirée (200x200 pixels dans ce cas)\n",
    "new_width = 200\n",
    "new_height = 200\n",
    "new_size = (new_width, new_height)\n",
    "\n",
    "# Redimensionner l'image\n",
    "resized_image = cv2.resize(image, new_size)\n",
    "\n",
    "# Afficher l'image redimensionnée\n",
    "resized = cv2.imshow('Image redimensionnee', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# afficher resized\n",
    "\n",
    "# qu'est ce que vous remarquez !!\n",
    "#L'image est devenue plus petite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redimensinner sans affecter l'image\n",
    "\n",
    "# Obtenir les dimensions de l'image originale\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Définir la nouvelle taille désirée (200x200 pixels dans ce cas)\n",
    "new_width = 200\n",
    "new_height = 200\n",
    "\n",
    "# Calculer le ratio de redimensionnement\n",
    "ratio_width = new_width / width\n",
    "ratio_height = new_height / height\n",
    "\n",
    "# Redimensionner l'image en conservant le ratio\n",
    "resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Afficher l'image redimensionnée\n",
    "cv2.imshow('Image redimensionnee', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire tourner une image -45°\n",
    "\n",
    "# Obtenir les dimensions de l'image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Définir l'angle de rotation en degrés (-45 dans ce cas)\n",
    "angle = -45\n",
    "\n",
    "# Calculer le centre de l'image\n",
    "center = (width // 2, height // 2)\n",
    "\n",
    "# Obtenir la matrice de rotation pour l'angle spécifié\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "# Appliquer la rotation à l'image\n",
    "rotated = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "\n",
    "# Afficher l'image rotatée\n",
    "cv2.imshow('Image rotatee', rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez utiliser la bibliothèque imutils pour faire les rotations et d'autres fonctions facilement. Pour l'instaler: pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dessiner sur l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dessiner un rectangle\n",
    "\n",
    "# Coordonnées du coin supérieur gauche du rectangle (x, y)\n",
    "start_point = (50, 50)\n",
    "\n",
    "# Coordonnées du coin inférieur droit du rectangle (x, y)\n",
    "end_point = (200, 200)\n",
    "\n",
    "# Couleur du rectangle en BGR (Bleu, Vert, Rouge)\n",
    "color = (255, 0, 0)  # Bleu\n",
    "\n",
    "# Épaisseur du bord du rectangle en pixels\n",
    "thickness = 2\n",
    "\n",
    "# Dessiner le rectangle sur l'image\n",
    "cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "# Afficher l'image avec le rectangle\n",
    "cv2.imshow('Image avec rectangle', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dessiner un circle\n",
    "\n",
    "# Coordonnées du centre du cercle (x, y)\n",
    "center_coordinates = (120, 100)\n",
    "\n",
    "# Rayon du cercle\n",
    "radius = 50\n",
    "\n",
    "# Couleur du cercle en BGR (Bleu, Vert, Rouge)\n",
    "color = (0, 255, 0)  # Vert\n",
    "\n",
    "# Épaisseur du trait du cercle\n",
    "# Pour un cercle plein, utilisez une épaisseur de -1\n",
    "thickness = 2\n",
    "\n",
    "# Dessiner le cercle sur l'image\n",
    "cv2.circle(image, center_coordinates, radius, color, thickness)\n",
    "\n",
    "# Afficher l'image avec le cercle\n",
    "cv2.imshow('Image avec cercle', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtrage d'image\n",
    "\n",
    "* Blur\n",
    "* Gaussian blur\n",
    "* Median blur\n",
    "* Sharpening\n",
    "* Bilateral blur\n",
    "* Bilateral filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charger et afficher l'image \"bois\"\n",
    "\n",
    "image1 = cv2.imread('bois.png',1)\n",
    "# afficher image\n",
    "cv2.imshow('Image Testing', image1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliser la méthode \"cv2.filter2D\" avec un kernel de taille 2\n",
    "\n",
    "kernel = np.array([[1, -1], [0, 1]], dtype=np.float32)\n",
    "\n",
    "# Appliquer le filtre 2D\n",
    "filtered_image = cv2.filter2D(image1, -1, kernel)\n",
    "\n",
    "# Afficher l'image originale et l'image filtrée\n",
    "cv2.imshow('Image originale', image1)\n",
    "cv2.imshow('Image filtree', filtered_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer blur avec un kernel de taille 5x5\n",
    "\n",
    "# Appliquer le flou avec un kernel de taille 5x5\n",
    "blurred_image = cv2.GaussianBlur(image1, (5, 5), 0)\n",
    "\n",
    "# Afficher l'image originale et l'image avec le flou appliqué\n",
    "cv2.imshow('Image originale', image1)\n",
    "cv2.imshow('Image avec flou', blurred_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian blur\n",
    "\n",
    "# Appliquer un flou gaussien\n",
    "# Le deuxième argument est la taille du kernel (width, height) qui doit être positif et impair.\n",
    "# Le troisième argument est la déviation standard dans la direction X; lorsque 0 est spécifié, elle est calculée à partir de la taille du kernel.\n",
    "blurred_image = cv2.GaussianBlur(image1, (5, 5), 0)\n",
    "\n",
    "# Afficher l'image originale et l'image floutée\n",
    "cv2.imshow('Image Originale', image1)\n",
    "cv2.imshow('Image avec Flou Gaussien', blurred_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median blur\n",
    "\n",
    "# Appliquer un flou médian avec un kernel de taille 5x5\n",
    "blurred_image = cv2.medianBlur(image1, 5)\n",
    "\n",
    "# Afficher l'image originale et l'image avec le flou médian appliqué\n",
    "cv2.imshow('Image Originale', image1)\n",
    "cv2.imshow('Image avec Flou Médian', blurred_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharpening\n",
    "\n",
    "# Définir le kernel de filtre de netteté\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1, 9, -1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "# Appliquer la convolution pour appliquer l'effet de netteté\n",
    "sharpened_image = cv2.filter2D(image1, -1, kernel)\n",
    "\n",
    "# Afficher l'image originale et l'image avec l'effet de netteté\n",
    "cv2.imshow('Image Originale', image1)\n",
    "cv2.imshow('Image avec Effet de Netteté', sharpened_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bilateral filtering\n",
    "\n",
    "# Appliquer le filtre bilatéral avec les paramètres spécifiés\n",
    "# Arguments : (image, diamètre du pixel, écart-type de la couleur, écart-type de l'espace)\n",
    "filtered_image = cv2.bilateralFilter(image1, 9, 75, 75)\n",
    "\n",
    "# Afficher l'image originale et l'image avec le filtre bilatéral appliqué\n",
    "cv2.imshow('Image Originale', image1)\n",
    "cv2.imshow('Image avec Filtre Bilatéral', filtered_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seuillage d'image\n",
    "\n",
    "En utilisant l'image \"sudoku\" appliquer:\n",
    "* Binary Thresholding\n",
    "* Otsu thresholding\n",
    "* Adaptive thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer un seuillage binaire d'un seuil de 127\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "gray_image = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Appliquer un seuillage binaire\n",
    "_, binary_threshold_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Afficher l'image en niveaux de gris et l'image après seuillage binaire\n",
    "cv2.imshow('Image en Niveaux de Gris', gray_image)\n",
    "cv2.imshow('Image après Seuillage Binaire', binary_threshold_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer un seuillage binaire d'un seuil de 30\n",
    "\n",
    "# Appliquer un seuillage binaire avec un seuil de 30\n",
    "_, binary_threshold_image = cv2.threshold(gray_image, 30, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Afficher l'image en niveaux de gris et l'image après seuillage binaire\n",
    "cv2.imshow('Image en Niveaux de Gris', gray_image)\n",
    "cv2.imshow('Image après Seuillage Binaire à 30', binary_threshold_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer un seuillage binaire d'un seuil de 240\n",
    "\n",
    "# Appliquer un seuillage binaire avec un seuil de 240\n",
    "_, binary_threshold_image = cv2.threshold(gray_image, 240, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Afficher l'image en niveaux de gris et l'image après seuillage binaire\n",
    "cv2.imshow('Image en Niveaux de Gris', gray_image)\n",
    "cv2.imshow('Image après Seuillage Binaire à 240', binary_threshold_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'est ce que vous remarquez ?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'image est devenue plus sombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer \"Otsu\" seuillage\n",
    "\n",
    "# Appliquer le seuillage d'Otsu\n",
    "_, otsu_threshold_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Afficher l'image en niveaux de gris et l'image après seuillage d'Otsu\n",
    "cv2.imshow('Image en Niveaux de Gris', gray_image)\n",
    "cv2.imshow('Image après Seuillage d\\'Otsu', otsu_threshold_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appliquer \"Adaptive threshold\"\n",
    "\n",
    "# Appliquer le seuillage adaptatif\n",
    "adaptive_threshold_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Afficher l'image en niveaux de gris et l'image après le seuillage adaptatif\n",
    "cv2.imshow('Image en Niveaux de Gris', gray_image)\n",
    "cv2.imshow('Image après Seuillage Adaptatif', adaptive_threshold_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection des bords\n",
    "\n",
    "* Sobel\n",
    "* Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utiliser la methode sobel pour détecter les bords\n",
    "# Vous pouvez utiliser d'autres images de votre choix\n",
    "\n",
    "image2 = cv2.imread('sudoku.jpg',1)\n",
    "# afficher image\n",
    "cv2.imshow('Image Testing', image2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Appliquer l'opérateur de Sobel pour calculer les gradients en x et en y\n",
    "sobel_x = cv2.Sobel(image2, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(image2, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Convertir les valeurs de gradient en valeurs absolues\n",
    "sobel_x = np.abs(sobel_x)\n",
    "sobel_y = np.abs(sobel_y)\n",
    "\n",
    "# Fusionner les gradients en x et en y pour obtenir le gradient total\n",
    "sobel_combined = cv2.addWeighted(sobel_x, 0.5, sobel_y, 0.5, 0)\n",
    "\n",
    "# Afficher les images des gradients et l'image combinée\n",
    "cv2.imshow('Gradient X', sobel_x.astype(np.uint8))\n",
    "cv2.imshow('Gradient Y', sobel_y.astype(np.uint8))\n",
    "cv2.imshow('Gradient combiné', sobel_combined.astype(np.uint8))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny\n",
    "\n",
    "gray_image = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "# Appliquer un flou Gaussien pour réduire le bruit et les faux positifs\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Appliquer la détection de bords Canny\n",
    "edges = cv2.Canny(blurred_image, 100, 200)\n",
    "\n",
    "# Afficher l'image originale et l'image avec les bords détectés\n",
    "cv2.imshow('Image Originale', image2)\n",
    "cv2.imshow('Bords Detectes avec Canny', edges)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection des contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charger l'image 02\n",
    "# faites une recherche sur internet pour détecter les contours des objets dans image_02\n",
    "\n",
    "image3 = cv2.imread('image_02.png',1)\n",
    "# afficher image\n",
    "cv2.imshow('Image Test', image3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "gray_image3 = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Appliquer un flou Gaussien pour réduire le bruit\n",
    "blurred_image3 = cv2.GaussianBlur(gray_image3, (5, 5), 0)\n",
    "\n",
    "# Appliquer la détection de bords Canny\n",
    "edges = cv2.Canny(blurred_image3, 100, 200)\n",
    "\n",
    "# Trouver les contours dans l'image\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Dessiner les contours sur une copie de l'image originale\n",
    "image_with_contours = image3.copy()\n",
    "cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Afficher l'image originale et l'image avec les contours détectés\n",
    "cv2.imshow('Image Originale', image3)\n",
    "cv2.imshow('Contours Detectes', image_with_contours)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Compter des objets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'objets détectés: 5\n"
     ]
    }
   ],
   "source": [
    "# Compter les objets\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "#gray_image3 = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Appliquer un flou Gaussien pour réduire le bruit\n",
    "blurred_image3 = cv2.GaussianBlur(gray_image3, (5, 5), 0)\n",
    "\n",
    "# Appliquer la détection de bords Canny\n",
    "edges = cv2.Canny(blurred_image3, 100, 200)\n",
    "# Trouver les contours dans l'image\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Afficher le nombre d'objets détectés (nombre de contours)\n",
    "print(\"Nombre d'objets détectés:\", len(contours))\n",
    "\n",
    "# Dessiner les contours sur une copie de l'image originale\n",
    "image_with_contours = image3.copy()\n",
    "cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Afficher l'image originale et l'image avec les contours détectés\n",
    "cv2.imshow('Image Originale', image3)\n",
    "cv2.imshow('Contours Detectes', image_with_contours)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "Compter le nombre d'objets dans l'image 03 avec le code précédent.\n",
    "- Qu'est ce que vous remarquez?\n",
    "- Utiliser l'algorithme Watershed pour detecter et séparer les objets connectés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'objets détectés: 4\n"
     ]
    }
   ],
   "source": [
    "image4 = cv2.imread('image_03.jpg',1)\n",
    "# afficher image\n",
    "cv2.imshow('Image Test', image4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convertir l'image en niveaux de gris\n",
    "gray_image4 = cv2.cvtColor(image4, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Appliquer un flou Gaussien pour réduire le bruit\n",
    "blurred_image4 = cv2.GaussianBlur(gray_image4, (5, 5), 0)\n",
    "\n",
    "# Appliquer la détection de bords Canny\n",
    "edges = cv2.Canny(blurred_image4, 100, 200)\n",
    "# Trouver les contours dans l'image\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Afficher le nombre d'objets détectés (nombre de contours)\n",
    "print(\"Nombre d'objets détectés:\", len(contours))\n",
    "\n",
    "# Dessiner les contours sur une copie de l'image originale\n",
    "image_with_contours = image4.copy()\n",
    "cv2.drawContours(image_with_contours, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Afficher l'image originale et l'image avec les contours détectés\n",
    "cv2.imshow('Image Originale', image4)\n",
    "cv2.imshow('Contours Detectes', image_with_contours)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bravo !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e29c752e75e91034d0c40602915a17cb0379d8f99d244b8deba46517b7d2192"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
